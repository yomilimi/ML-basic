{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. start tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#create a constant op\n",
    "#this op is added as a node to the default graph\n",
    "hello=tf.constant('Hello, TensorFlow!')\n",
    "print(hello.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: tf.Tensor(3.0, shape=(), dtype=float32) node2 tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "node3: tf.Tensor(7.0, shape=(), dtype=float32)\n",
      "node1: 3.0 node2: 4.0\n",
      "node3: 7.0\n"
     ]
    }
   ],
   "source": [
    "#computational Graph\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0, tf.float32)\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(\"node1:\",node1, \"node2\", node2)\n",
    "print(\"node3:\",node3)\n",
    "\n",
    "print(\"node1:\", node1.numpy(), \"node2:\", node2.numpy())\n",
    "print(\"node3:\", node3.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"#placeholder였는데... 이젠 안씀\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a+b\n",
    "\n",
    "print(sess.run(adder_node, feed_dict={a:3, b:4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a:[1,3], b:[2,4]}))\"\"\"\n",
    "\n",
    "#즉시 실행\n",
    "a = tf.constant(3.0, tf.float32)\n",
    "b = tf.constant(4.5, tf.float32)\n",
    "adder_node = a + b\n",
    "\n",
    "print(adder_node.numpy())\n",
    "\n",
    "a = tf.constant([1,3], tf.float32)\n",
    "b = tf.constant([2,4], tf.float32)\n",
    "adder_node = a + b\n",
    "print(adder_node.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TensorFlow로 간단한 linear regresson 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.2993684 [-0.16863056] [0.13092566]\n",
      "20 0.104035795 [0.68479824] [0.47603747]\n",
      "40 0.035323355 [0.77564496] [0.4871126]\n",
      "60 0.031544805 [0.79342854] [0.467405]\n",
      "80 0.028644642 [0.803826] [0.44574198]\n",
      "100 0.026015459 [0.8131111] [0.42482254]\n",
      "120 0.023627654 [0.8219005] [0.4048602]\n",
      "140 0.021459028 [0.8302711] [0.38583353]\n",
      "160 0.019489428 [0.8382478] [0.3677008]\n",
      "180 0.01770062 [0.8458495] [0.35042024]\n",
      "200 0.016075984 [0.85309404] [0.33395174]\n",
      "220 0.014600462 [0.85999805] [0.31825724]\n",
      "240 0.01326039 [0.8665776] [0.30330032]\n",
      "260 0.012043283 [0.87284803] [0.28904638]\n",
      "280 0.010937899 [0.8788237] [0.27546227]\n",
      "300 0.009933977 [0.88451856] [0.26251653]\n",
      "320 0.009022205 [0.88994575] [0.2501792]\n",
      "340 0.008194101 [0.8951179] [0.23842172]\n",
      "360 0.0074420124 [0.90004694] [0.22721678]\n",
      "380 0.006758956 [0.9047444] [0.21653843]\n",
      "400 0.006138601 [0.90922105] [0.20636193]\n",
      "420 0.0055751726 [0.9134873] [0.1966637]\n",
      "440 0.005063464 [0.917553] [0.18742125]\n",
      "460 0.004598717 [0.9214278] [0.17861313]\n",
      "480 0.0041766376 [0.9251204] [0.17021896]\n",
      "500 0.0037932817 [0.9286395] [0.16221926]\n",
      "520 0.0034451175 [0.9319931] [0.15459555]\n",
      "540 0.0031289132 [0.9351892] [0.14733012]\n",
      "560 0.002841729 [0.938235] [0.14040618]\n",
      "580 0.0025809072 [0.9411378] [0.13380766]\n",
      "600 0.0023440234 [0.9439041] [0.12751918]\n",
      "620 0.0021288723 [0.9465404] [0.12152623]\n",
      "640 0.0019334764 [0.94905293] [0.11581493]\n",
      "660 0.0017560128 [0.95144725] [0.11037197]\n",
      "680 0.0015948449 [0.953729] [0.10518489]\n",
      "700 0.0014484545 [0.95590353] [0.1002416]\n",
      "720 0.0013155093 [0.95797586] [0.09553062]\n",
      "740 0.0011947717 [0.959951] [0.09104101]\n",
      "760 0.0010851071 [0.96183306] [0.08676239]\n",
      "780 0.0009855126 [0.9636268] [0.08268488]\n",
      "800 0.0008950603 [0.96533614] [0.07879902]\n",
      "820 0.0008129065 [0.96696526] [0.07509577]\n",
      "840 0.00073829666 [0.9685177] [0.07156654]\n",
      "860 0.000670533 [0.9699974] [0.06820317]\n",
      "880 0.0006089846 [0.9714074] [0.06499782]\n",
      "900 0.00055309036 [0.97275114] [0.06194314]\n",
      "920 0.00050232466 [0.9740317] [0.05903204]\n",
      "940 0.00045622024 [0.97525215] [0.05625776]\n",
      "960 0.0004143467 [0.97641516] [0.05361383]\n",
      "980 0.00037631553 [0.97752357] [0.05109419]\n",
      "1000 0.00034177848 [0.9785798] [0.04869299]\n",
      "1020 0.0003104078 [0.9795864] [0.04640464]\n",
      "1040 0.00028191725 [0.9805459] [0.04422377]\n",
      "1060 0.00025604182 [0.98146015] [0.04214542]\n",
      "1080 0.00023254172 [0.98233145] [0.04016472]\n",
      "1100 0.00021119633 [0.9831618] [0.03827713]\n",
      "1120 0.00019181128 [0.9839532] [0.03647825]\n",
      "1140 0.00017420649 [0.9847073] [0.03476389]\n",
      "1160 0.00015821717 [0.985426] [0.03313011]\n",
      "1180 0.00014369673 [0.986111] [0.03157312]\n",
      "1200 0.00013050747 [0.98676366] [0.03008929]\n",
      "1220 0.000118528646 [0.9873857] [0.02867521]\n",
      "1240 0.00010765029 [0.9879785] [0.0273276]\n",
      "1260 9.77697e-05 [0.98854345] [0.02604333]\n",
      "1280 8.8795445e-05 [0.98908186] [0.0248194]\n",
      "1300 8.064639e-05 [0.98959506] [0.02365302]\n",
      "1320 7.324415e-05 [0.9900842] [0.02254134]\n",
      "1340 6.6520595e-05 [0.99055016] [0.02148192]\n",
      "1360 6.0415045e-05 [0.9909943] [0.02047231]\n",
      "1380 5.4869462e-05 [0.99141747] [0.01951016]\n",
      "1400 4.983306e-05 [0.99182075] [0.01859326]\n",
      "1420 4.525899e-05 [0.99220514] [0.01771946]\n",
      "1440 4.1105533e-05 [0.9925715] [0.01688672]\n",
      "1460 3.7333044e-05 [0.99292064] [0.01609309]\n",
      "1480 3.3906297e-05 [0.99325335] [0.01533677]\n",
      "1500 3.0793988e-05 [0.99357045] [0.01461598]\n",
      "1520 2.7967746e-05 [0.9938726] [0.01392906]\n",
      "1540 2.5400877e-05 [0.9941606] [0.01327443]\n",
      "1560 2.3069146e-05 [0.994435] [0.01265059]\n",
      "1580 2.0951484e-05 [0.9946965] [0.01205605]\n",
      "1600 1.9028994e-05 [0.99494565] [0.01148951]\n",
      "1620 1.72825e-05 [0.99518335] [0.01094955]\n",
      "1640 1.5696241e-05 [0.9954096] [0.01043496]\n",
      "1660 1.4255637e-05 [0.9956254] [0.00994457]\n",
      "1680 1.2947282e-05 [0.99583095] [0.00947722]\n",
      "1700 1.17586305e-05 [0.9960269] [0.00903185]\n",
      "1720 1.0679192e-05 [0.99621356] [0.00860738]\n",
      "1740 9.699385e-06 [0.99639153] [0.00820289]\n",
      "1760 8.80906e-06 [0.99656105] [0.0078174]\n",
      "1780 8.00104e-06 [0.9967227] [0.00745006]\n",
      "1800 7.266186e-06 [0.9968767] [0.00709994]\n",
      "1820 6.5996683e-06 [0.9970235] [0.00676627]\n",
      "1840 5.9938575e-06 [0.99716336] [0.00644829]\n",
      "1860 5.443688e-06 [0.9972967] [0.00614526]\n",
      "1880 4.943781e-06 [0.9974237] [0.00585645]\n",
      "1900 4.4900776e-06 [0.99754477] [0.00558124]\n",
      "1920 4.077979e-06 [0.9976602] [0.00531895]\n",
      "1940 3.7040384e-06 [0.99777013] [0.00506898]\n",
      "1960 3.3638516e-06 [0.99787486] [0.00483078]\n",
      "1980 3.0552274e-06 [0.9979748] [0.00460377]\n"
     ]
    }
   ],
   "source": [
    "#build graph: H(x)=Wx+b\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), name='weight') #random한 값을 1차원으로 줌\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "#가설 함수 정의\n",
    "def hypothesis(x):\n",
    "    return x*W + b #our hypothesis XW+b\n",
    "\n",
    "#cost/loss function\n",
    "def loss_function(hypothesis, y):\n",
    "    return tf.reduce_mean(tf.square(hypothesis-y_train)) #square: 제곱, reduce_mean: 평균\n",
    "\n",
    "#gradient descent: minimize cost\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "#train = optimizer.minimize(cost) tensorflow 2.x에서는 minimize 사용안됨\n",
    "\n",
    "# 학습\n",
    "epochs = 2000\n",
    "for step in range(epochs):\n",
    "    # Gradient 계산 및 변수 업데이트\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss_function(hypothesis(x_train), y_train)\n",
    "    gradients = tape.gradient(current_loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    \n",
    "    # 로그 출력\n",
    "    if step % 20 == 0:\n",
    "        print(step, current_loss.numpy(), W.numpy(), b.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과\n",
    "정답: W=1, b=0\n",
    "loss가 점점 줄어들고 W=1에, b=0에 수렴함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. linear regresson의 cost 최소화의 TensorFlow 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1., 2., 3.], dtype=np.float32)\n",
    "Y = np.array([1., 2., 3.], dtype=np.float32)\n",
    "\n",
    "W = tf.Variable(0.)\n",
    "\n",
    "@tf.function\n",
    "def hypothesis(X):\n",
    "    return X * W\n",
    "\n",
    "def cost_func():\n",
    "    return tf.reduce_mean(tf.square(hypothesis(X) - Y))\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "\n",
    "for i in range(-30,50):\n",
    "    W.assign(i*0.1) #W를 -3에서 5까지 움직임\n",
    "    curr_cost = cost_func()\n",
    "    W_val.append(W.numpy()) #현재 W값을 리스트에 추가\n",
    "    cost_val.append(curr_cost.numpy()) #현재 비용함수 값 리스트에 추가\n",
    "\n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X = [1., 2., 3.]\n",
    "Y = [1., 2., 3.]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]),name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X*W\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(hypothesis-Y))\n",
    "\n",
    "#minimize: gradient descent using derivative: W-=learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W*X-Y)*X) #(W*X-Y)^2 미분 값\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\"\"\"#minimize: Gradient Descent Maic\n",
    "optimizer = tf.train.GradietDescentOptimizer(learning_rate=0.1)\n",
    "train=optimizer.minimize(cost)\"\"\"\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.00044010626 5.0\n",
      "1 224.0 3.88\n",
      "2 116.121605 3.0736\n",
      "3 60.19744 2.492992\n",
      "4 31.206348 2.0749543\n",
      "5 16.177376 1.773967\n",
      "6 8.386351 1.5572562\n",
      "7 4.347483 1.4012245\n",
      "8 2.253735 1.2888817\n",
      "9 1.1683364 1.2079948\n",
      "10 0.6056657 1.1497563\n",
      "11 0.31397724 1.1078246\n",
      "12 0.16276592 1.0776337\n",
      "13 0.08437791 1.0558963\n",
      "14 0.04374152 1.0402453\n",
      "15 0.022675574 1.0289766\n",
      "16 0.011754995 1.020863\n",
      "17 0.0060937395 1.0150214\n",
      "18 0.0031590234 1.0108154\n",
      "19 0.0016376148 1.0077871\n",
      "20 0.0008489413 1.0056068\n"
     ]
    }
   ],
   "source": [
    "#tensorflow 2.0\n",
    "import tensorflow as tf\n",
    "\n",
    "X = [1., 2., 3.]\n",
    "Y = [1., 2., 3.]\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), name='weight')\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "for step in range(1,21):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * X\n",
    "        cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "    W_grad = tape.gradient(cost, W) #gradient = tf.reduce_mean((W*X-Y)*X)에 해당: (W*X-Y)^2 미분 값\n",
    "    W.assign_sub(learning_rate * W_grad)#descent = W - learning_rate * gradient에 해당\n",
    "    print(step, cost.numpy(), W.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.0\n",
      "1 1.2666664\n",
      "2 1.0177778\n",
      "3 1.0011852\n",
      "4 1.000079\n",
      "5 1.0000052\n",
      "6 1.0000004\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n",
      "100 1.0\n"
     ]
    }
   ],
   "source": [
    "#초기 W를 5.0으로 설정\n",
    "import tensorflow as tf\n",
    "\n",
    "X = [1., 2., 3.]\n",
    "Y = [1., 2., 3.]\n",
    "\n",
    "W = tf.Variable(5.0)\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.1) # SGD: Stochastic Gradient Descent\n",
    "\n",
    "print(0, W.numpy())\n",
    "for step in range(1,101):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * X\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    \n",
    "    gradients = tape.gradient(cost, [W])\n",
    "    optimizer.apply_gradients(zip(gradients, [W]))\n",
    "    print(step, W.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18.666666 5.0\n",
      "1 37.333332 1.2666664 37.333336\n",
      "2 2.4888866 1.0177778 2.4888866\n",
      "3 0.1659259 1.0011852 0.1659259\n",
      "4 0.011061668 1.000079 0.011061668\n",
      "5 0.00073742867 1.0000052 0.00073742867\n",
      "6 4.895528e-05 1.0000004 4.8955284e-05\n",
      "7 3.0994415e-06 1.0 3.0994415e-06\n",
      "8 0.0 1.0 0.0\n",
      "9 0.0 1.0 0.0\n",
      "10 0.0 1.0 0.0\n",
      "11 0.0 1.0 0.0\n",
      "12 0.0 1.0 0.0\n",
      "13 0.0 1.0 0.0\n",
      "14 0.0 1.0 0.0\n",
      "15 0.0 1.0 0.0\n",
      "16 0.0 1.0 0.0\n",
      "17 0.0 1.0 0.0\n",
      "18 0.0 1.0 0.0\n",
      "19 0.0 1.0 0.0\n",
      "20 0.0 1.0 0.0\n",
      "21 0.0 1.0 0.0\n",
      "22 0.0 1.0 0.0\n",
      "23 0.0 1.0 0.0\n",
      "24 0.0 1.0 0.0\n",
      "25 0.0 1.0 0.0\n",
      "26 0.0 1.0 0.0\n",
      "27 0.0 1.0 0.0\n",
      "28 0.0 1.0 0.0\n",
      "29 0.0 1.0 0.0\n",
      "30 0.0 1.0 0.0\n",
      "31 0.0 1.0 0.0\n",
      "32 0.0 1.0 0.0\n",
      "33 0.0 1.0 0.0\n",
      "34 0.0 1.0 0.0\n",
      "35 0.0 1.0 0.0\n",
      "36 0.0 1.0 0.0\n",
      "37 0.0 1.0 0.0\n",
      "38 0.0 1.0 0.0\n",
      "39 0.0 1.0 0.0\n",
      "40 0.0 1.0 0.0\n",
      "41 0.0 1.0 0.0\n",
      "42 0.0 1.0 0.0\n",
      "43 0.0 1.0 0.0\n",
      "44 0.0 1.0 0.0\n",
      "45 0.0 1.0 0.0\n",
      "46 0.0 1.0 0.0\n",
      "47 0.0 1.0 0.0\n",
      "48 0.0 1.0 0.0\n",
      "49 0.0 1.0 0.0\n",
      "50 0.0 1.0 0.0\n",
      "51 0.0 1.0 0.0\n",
      "52 0.0 1.0 0.0\n",
      "53 0.0 1.0 0.0\n",
      "54 0.0 1.0 0.0\n",
      "55 0.0 1.0 0.0\n",
      "56 0.0 1.0 0.0\n",
      "57 0.0 1.0 0.0\n",
      "58 0.0 1.0 0.0\n",
      "59 0.0 1.0 0.0\n",
      "60 0.0 1.0 0.0\n",
      "61 0.0 1.0 0.0\n",
      "62 0.0 1.0 0.0\n",
      "63 0.0 1.0 0.0\n",
      "64 0.0 1.0 0.0\n",
      "65 0.0 1.0 0.0\n",
      "66 0.0 1.0 0.0\n",
      "67 0.0 1.0 0.0\n",
      "68 0.0 1.0 0.0\n",
      "69 0.0 1.0 0.0\n",
      "70 0.0 1.0 0.0\n",
      "71 0.0 1.0 0.0\n",
      "72 0.0 1.0 0.0\n",
      "73 0.0 1.0 0.0\n",
      "74 0.0 1.0 0.0\n",
      "75 0.0 1.0 0.0\n",
      "76 0.0 1.0 0.0\n",
      "77 0.0 1.0 0.0\n",
      "78 0.0 1.0 0.0\n",
      "79 0.0 1.0 0.0\n",
      "80 0.0 1.0 0.0\n",
      "81 0.0 1.0 0.0\n",
      "82 0.0 1.0 0.0\n",
      "83 0.0 1.0 0.0\n",
      "84 0.0 1.0 0.0\n",
      "85 0.0 1.0 0.0\n",
      "86 0.0 1.0 0.0\n",
      "87 0.0 1.0 0.0\n",
      "88 0.0 1.0 0.0\n",
      "89 0.0 1.0 0.0\n",
      "90 0.0 1.0 0.0\n",
      "91 0.0 1.0 0.0\n",
      "92 0.0 1.0 0.0\n",
      "93 0.0 1.0 0.0\n",
      "94 0.0 1.0 0.0\n",
      "95 0.0 1.0 0.0\n",
      "96 0.0 1.0 0.0\n",
      "97 0.0 1.0 0.0\n",
      "98 0.0 1.0 0.0\n",
      "99 0.0 1.0 0.0\n",
      "100 0.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "#직접 계산한 gradient와 optimizer로 계산한 gradient가 같은지 비교\n",
    "import tensorflow as tf\n",
    "\n",
    "X = [1., 2., 3.]\n",
    "Y = [1., 2., 3.]\n",
    "\n",
    "W = tf.Variable(5.)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "print(0, tf.reduce_mean((W * X - Y) * X).numpy(), W.numpy())\n",
    "for step in range(1,101):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * X\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "    # Get gradients\n",
    "    W_grad = tape.gradient(cost, W)\n",
    "    \n",
    "    # Calculate gradient manually: 수동으로 gradient 계산\n",
    "    gradient_manual = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "\n",
    "    # Update W using optimizer\n",
    "    optimizer.apply_gradients(zip([W_grad], [W]))\n",
    "\n",
    "    print(step, gradient_manual.numpy(), W.numpy(), W_grad.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. multi-variable linear regression을 TensorFlow에서 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  221075.38 \n",
      "Prediction:\n",
      " [[-260.95798]\n",
      " [-319.91367]\n",
      " [-311.8621 ]\n",
      " [-341.88004]\n",
      " [-243.5665 ]]\n",
      "10 Cost:  10.886541 \n",
      "Prediction:\n",
      " [[154.95697]\n",
      " [180.00662]\n",
      " [180.7067 ]\n",
      " [194.51657]\n",
      " [137.75085]]\n",
      "20 Cost:  8.817249 \n",
      "Prediction:\n",
      " [[156.20403]\n",
      " [181.52695]\n",
      " [182.19351]\n",
      " [196.13722]\n",
      " [138.91455]]\n",
      "30 Cost:  8.771856 \n",
      "Prediction:\n",
      " [[156.19646]\n",
      " [181.53929]\n",
      " [182.1945 ]\n",
      " [196.13985]\n",
      " [138.92801]]\n",
      "40 Cost:  8.726764 \n",
      "Prediction:\n",
      " [[156.18515]\n",
      " [181.54706]\n",
      " [182.19102]\n",
      " [196.1376 ]\n",
      " [138.93797]]\n",
      "50 Cost:  8.681923 \n",
      "Prediction:\n",
      " [[156.17384]\n",
      " [181.55476]\n",
      " [182.18752]\n",
      " [196.13531]\n",
      " [138.94788]]\n",
      "60 Cost:  8.637323 \n",
      "Prediction:\n",
      " [[156.16258]\n",
      " [181.56248]\n",
      " [182.18404]\n",
      " [196.13306]\n",
      " [138.95775]]\n",
      "70 Cost:  8.5929785 \n",
      "Prediction:\n",
      " [[156.15135]\n",
      " [181.57014]\n",
      " [182.18056]\n",
      " [196.13081]\n",
      " [138.96762]]\n",
      "80 Cost:  8.548809 \n",
      "Prediction:\n",
      " [[156.14012]\n",
      " [181.5778 ]\n",
      " [182.17708]\n",
      " [196.12856]\n",
      " [138.97745]]\n",
      "90 Cost:  8.50492 \n",
      "Prediction:\n",
      " [[156.12894]\n",
      " [181.58545]\n",
      " [182.17363]\n",
      " [196.12631]\n",
      " [138.98724]]\n",
      "100 Cost:  8.461246 \n",
      "Prediction:\n",
      " [[156.1178 ]\n",
      " [181.59308]\n",
      " [182.17018]\n",
      " [196.1241 ]\n",
      " [138.99704]]\n",
      "110 Cost:  8.417835 \n",
      "Prediction:\n",
      " [[156.10667]\n",
      " [181.60066]\n",
      " [182.16672]\n",
      " [196.12184]\n",
      " [139.00677]]\n",
      "120 Cost:  8.37466 \n",
      "Prediction:\n",
      " [[156.0956 ]\n",
      " [181.60825]\n",
      " [182.1633 ]\n",
      " [196.11964]\n",
      " [139.01651]]\n",
      "130 Cost:  8.331663 \n",
      "Prediction:\n",
      " [[156.08452]\n",
      " [181.6158 ]\n",
      " [182.15987]\n",
      " [196.11742]\n",
      " [139.02621]]\n",
      "140 Cost:  8.288946 \n",
      "Prediction:\n",
      " [[156.07349]\n",
      " [181.62334]\n",
      " [182.15645]\n",
      " [196.1152 ]\n",
      " [139.03587]]\n",
      "150 Cost:  8.246506 \n",
      "Prediction:\n",
      " [[156.0625 ]\n",
      " [181.63084]\n",
      " [182.15306]\n",
      " [196.113  ]\n",
      " [139.04552]]\n",
      "160 Cost:  8.204223 \n",
      "Prediction:\n",
      " [[156.05153]\n",
      " [181.63835]\n",
      " [182.14967]\n",
      " [196.11082]\n",
      " [139.05515]]\n",
      "170 Cost:  8.162184 \n",
      "Prediction:\n",
      " [[156.04059]\n",
      " [181.64583]\n",
      " [182.14627]\n",
      " [196.10861]\n",
      " [139.06473]]\n",
      "180 Cost:  8.120349 \n",
      "Prediction:\n",
      " [[156.02966]\n",
      " [181.65329]\n",
      " [182.1429 ]\n",
      " [196.10643]\n",
      " [139.0743 ]]\n",
      "190 Cost:  8.078812 \n",
      "Prediction:\n",
      " [[156.01877]\n",
      " [181.66069]\n",
      " [182.13953]\n",
      " [196.10426]\n",
      " [139.08382]]\n",
      "200 Cost:  8.037412 \n",
      "Prediction:\n",
      " [[156.00792]\n",
      " [181.66814]\n",
      " [182.13617]\n",
      " [196.1021 ]\n",
      " [139.09334]]\n",
      "210 Cost:  7.9962807 \n",
      "Prediction:\n",
      " [[155.99709]\n",
      " [181.67552]\n",
      " [182.13281]\n",
      " [196.0999 ]\n",
      " [139.10281]]\n",
      "220 Cost:  7.9554033 \n",
      "Prediction:\n",
      " [[155.9863 ]\n",
      " [181.68288]\n",
      " [182.12949]\n",
      " [196.09776]\n",
      " [139.11229]]\n",
      "230 Cost:  7.9146934 \n",
      "Prediction:\n",
      " [[155.97552]\n",
      " [181.69025]\n",
      " [182.12616]\n",
      " [196.09563]\n",
      " [139.12172]]\n",
      "240 Cost:  7.874199 \n",
      "Prediction:\n",
      " [[155.96478]\n",
      " [181.69759]\n",
      " [182.12283]\n",
      " [196.09349]\n",
      " [139.13113]]\n",
      "250 Cost:  7.8339515 \n",
      "Prediction:\n",
      " [[155.95409]\n",
      " [181.7049 ]\n",
      " [182.11948]\n",
      " [196.09132]\n",
      " [139.1405 ]]\n",
      "260 Cost:  7.7938833 \n",
      "Prediction:\n",
      " [[155.94339]\n",
      " [181.7122 ]\n",
      " [182.11618]\n",
      " [196.08919]\n",
      " [139.14986]]\n",
      "270 Cost:  7.754073 \n",
      "Prediction:\n",
      " [[155.93275]\n",
      " [181.71948]\n",
      " [182.1129 ]\n",
      " [196.08707]\n",
      " [139.15921]]\n",
      "280 Cost:  7.7144904 \n",
      "Prediction:\n",
      " [[155.92213]\n",
      " [181.72673]\n",
      " [182.1096 ]\n",
      " [196.08495]\n",
      " [139.1685 ]]\n",
      "290 Cost:  7.6751266 \n",
      "Prediction:\n",
      " [[155.91153]\n",
      " [181.73395]\n",
      " [182.10632]\n",
      " [196.08286]\n",
      " [139.17776]]\n",
      "300 Cost:  7.635896 \n",
      "Prediction:\n",
      " [[155.90096]\n",
      " [181.74118]\n",
      " [182.10304]\n",
      " [196.08073]\n",
      " [139.18703]]\n",
      "310 Cost:  7.596906 \n",
      "Prediction:\n",
      " [[155.89043]\n",
      " [181.7484 ]\n",
      " [182.0998 ]\n",
      " [196.07864]\n",
      " [139.19627]]\n",
      "320 Cost:  7.558155 \n",
      "Prediction:\n",
      " [[155.87991]\n",
      " [181.75557]\n",
      " [182.09654]\n",
      " [196.07654]\n",
      " [139.20547]]\n",
      "330 Cost:  7.5196037 \n",
      "Prediction:\n",
      " [[155.86943]\n",
      " [181.76274]\n",
      " [182.0933 ]\n",
      " [196.07446]\n",
      " [139.21465]]\n",
      "340 Cost:  7.481243 \n",
      "Prediction:\n",
      " [[155.85896]\n",
      " [181.76987]\n",
      " [182.09006]\n",
      " [196.07237]\n",
      " [139.2238 ]]\n",
      "350 Cost:  7.443123 \n",
      "Prediction:\n",
      " [[155.84854]\n",
      " [181.77698]\n",
      " [182.08682]\n",
      " [196.0703 ]\n",
      " [139.23293]]\n",
      "360 Cost:  7.405163 \n",
      "Prediction:\n",
      " [[155.83815]\n",
      " [181.7841 ]\n",
      " [182.0836 ]\n",
      " [196.06822]\n",
      " [139.24203]]\n",
      "370 Cost:  7.3674498 \n",
      "Prediction:\n",
      " [[155.82777]\n",
      " [181.79118]\n",
      " [182.0804 ]\n",
      " [196.06616]\n",
      " [139.2511 ]]\n",
      "380 Cost:  7.3299017 \n",
      "Prediction:\n",
      " [[155.81743]\n",
      " [181.79825]\n",
      " [182.07721]\n",
      " [196.0641 ]\n",
      " [139.26018]]\n",
      "390 Cost:  7.2926116 \n",
      "Prediction:\n",
      " [[155.80711]\n",
      " [181.80528]\n",
      " [182.074  ]\n",
      " [196.06204]\n",
      " [139.26918]]\n",
      "400 Cost:  7.2554445 \n",
      "Prediction:\n",
      " [[155.79681]\n",
      " [181.81232]\n",
      " [182.0708 ]\n",
      " [196.06   ]\n",
      " [139.27818]]\n",
      "410 Cost:  7.218522 \n",
      "Prediction:\n",
      " [[155.78656]\n",
      " [181.81934]\n",
      " [182.06764]\n",
      " [196.05797]\n",
      " [139.28717]]\n",
      "420 Cost:  7.181792 \n",
      "Prediction:\n",
      " [[155.77634]\n",
      " [181.82632]\n",
      " [182.06445]\n",
      " [196.05592]\n",
      " [139.29613]]\n",
      "430 Cost:  7.1452928 \n",
      "Prediction:\n",
      " [[155.76613]\n",
      " [181.83328]\n",
      " [182.06131]\n",
      " [196.05391]\n",
      " [139.30505]]\n",
      "440 Cost:  7.1089616 \n",
      "Prediction:\n",
      " [[155.75595]\n",
      " [181.84023]\n",
      " [182.05815]\n",
      " [196.05188]\n",
      " [139.31396]]\n",
      "450 Cost:  7.0728064 \n",
      "Prediction:\n",
      " [[155.7458 ]\n",
      " [181.84717]\n",
      " [182.055  ]\n",
      " [196.04987]\n",
      " [139.32285]]\n",
      "460 Cost:  7.0368814 \n",
      "Prediction:\n",
      " [[155.73567]\n",
      " [181.85408]\n",
      " [182.05188]\n",
      " [196.04785]\n",
      " [139.3317 ]]\n",
      "470 Cost:  7.0010896 \n",
      "Prediction:\n",
      " [[155.72557]\n",
      " [181.861  ]\n",
      " [182.04874]\n",
      " [196.04585]\n",
      " [139.34053]]\n",
      "480 Cost:  6.96559 \n",
      "Prediction:\n",
      " [[155.71552]\n",
      " [181.86786]\n",
      " [182.04564]\n",
      " [196.04385]\n",
      " [139.34933]]\n",
      "490 Cost:  6.9301963 \n",
      "Prediction:\n",
      " [[155.70546]\n",
      " [181.87471]\n",
      " [182.04251]\n",
      " [196.04185]\n",
      " [139.35812]]\n",
      "500 Cost:  6.8950224 \n",
      "Prediction:\n",
      " [[155.69545]\n",
      " [181.88156]\n",
      " [182.03941]\n",
      " [196.03987]\n",
      " [139.36688]]\n",
      "510 Cost:  6.8600683 \n",
      "Prediction:\n",
      " [[155.68546]\n",
      " [181.88837]\n",
      " [182.03633]\n",
      " [196.03789]\n",
      " [139.37561]]\n",
      "520 Cost:  6.825258 \n",
      "Prediction:\n",
      " [[155.67549]\n",
      " [181.89517]\n",
      " [182.03323]\n",
      " [196.03592]\n",
      " [139.38432]]\n",
      "530 Cost:  6.7906356 \n",
      "Prediction:\n",
      " [[155.66557]\n",
      " [181.90198]\n",
      " [182.03015]\n",
      " [196.03395]\n",
      " [139.39302]]\n",
      "540 Cost:  6.7562585 \n",
      "Prediction:\n",
      " [[155.65565]\n",
      " [181.90872]\n",
      " [182.02708]\n",
      " [196.03198]\n",
      " [139.40166]]\n",
      "550 Cost:  6.7220154 \n",
      "Prediction:\n",
      " [[155.64577]\n",
      " [181.91547]\n",
      " [182.02403]\n",
      " [196.03003]\n",
      " [139.41031]]\n",
      "560 Cost:  6.6879473 \n",
      "Prediction:\n",
      " [[155.63591]\n",
      " [181.9222 ]\n",
      " [182.02097]\n",
      " [196.02808]\n",
      " [139.41893]]\n",
      "570 Cost:  6.654036 \n",
      "Prediction:\n",
      " [[155.62608]\n",
      " [181.92894]\n",
      " [182.01793]\n",
      " [196.02612]\n",
      " [139.42754]]\n",
      "580 Cost:  6.620387 \n",
      "Prediction:\n",
      " [[155.61629]\n",
      " [181.93562]\n",
      " [182.01488]\n",
      " [196.02422]\n",
      " [139.43608]]\n",
      "590 Cost:  6.5868845 \n",
      "Prediction:\n",
      " [[155.60649]\n",
      " [181.94229]\n",
      " [182.01187]\n",
      " [196.02226]\n",
      " [139.44463]]\n",
      "600 Cost:  6.55355 \n",
      "Prediction:\n",
      " [[155.59674]\n",
      " [181.94894]\n",
      " [182.00882]\n",
      " [196.02034]\n",
      " [139.45314]]\n",
      "610 Cost:  6.520387 \n",
      "Prediction:\n",
      " [[155.58702]\n",
      " [181.9556 ]\n",
      " [182.00581]\n",
      " [196.01842]\n",
      " [139.46165]]\n",
      "620 Cost:  6.4874406 \n",
      "Prediction:\n",
      " [[155.57733]\n",
      " [181.96222]\n",
      " [182.0028 ]\n",
      " [196.01651]\n",
      " [139.47012]]\n",
      "630 Cost:  6.4546776 \n",
      "Prediction:\n",
      " [[155.56766]\n",
      " [181.96883]\n",
      " [181.99983]\n",
      " [196.01459]\n",
      " [139.47856]]\n",
      "640 Cost:  6.4220376 \n",
      "Prediction:\n",
      " [[155.558  ]\n",
      " [181.9754 ]\n",
      " [181.99683]\n",
      " [196.01268]\n",
      " [139.487  ]]\n",
      "650 Cost:  6.389606 \n",
      "Prediction:\n",
      " [[155.54839]\n",
      " [181.98198]\n",
      " [181.99385]\n",
      " [196.01079]\n",
      " [139.4954 ]]\n",
      "660 Cost:  6.3573213 \n",
      "Prediction:\n",
      " [[155.53879]\n",
      " [181.98854]\n",
      " [181.99086]\n",
      " [196.0089 ]\n",
      " [139.50378]]\n",
      "670 Cost:  6.325256 \n",
      "Prediction:\n",
      " [[155.5292 ]\n",
      " [181.99504]\n",
      " [181.9879 ]\n",
      " [196.007  ]\n",
      " [139.51215]]\n",
      "680 Cost:  6.293322 \n",
      "Prediction:\n",
      " [[155.51968]\n",
      " [182.00159]\n",
      " [181.98495]\n",
      " [196.00513]\n",
      " [139.52051]]\n",
      "690 Cost:  6.261607 \n",
      "Prediction:\n",
      " [[155.51016]\n",
      " [182.00807]\n",
      " [181.98201]\n",
      " [196.00325]\n",
      " [139.52881]]\n",
      "700 Cost:  6.23005 \n",
      "Prediction:\n",
      " [[155.50067]\n",
      " [182.01456]\n",
      " [181.97906]\n",
      " [196.00137]\n",
      " [139.53708]]\n",
      "710 Cost:  6.1986 \n",
      "Prediction:\n",
      " [[155.4912 ]\n",
      " [182.02104]\n",
      " [181.97612]\n",
      " [195.99951]\n",
      " [139.54535]]\n",
      "720 Cost:  6.1673765 \n",
      "Prediction:\n",
      " [[155.48175]\n",
      " [182.02747]\n",
      " [181.97319]\n",
      " [195.99763]\n",
      " [139.5536 ]]\n",
      "730 Cost:  6.136322 \n",
      "Prediction:\n",
      " [[155.47234]\n",
      " [182.03389]\n",
      " [181.97028]\n",
      " [195.99579]\n",
      " [139.56183]]\n",
      "740 Cost:  6.105402 \n",
      "Prediction:\n",
      " [[155.46294]\n",
      " [182.04031]\n",
      " [181.96736]\n",
      " [195.99394]\n",
      " [139.57002]]\n",
      "750 Cost:  6.0746546 \n",
      "Prediction:\n",
      " [[155.45357]\n",
      " [182.04672]\n",
      " [181.96445]\n",
      " [195.9921 ]\n",
      " [139.57819]]\n",
      "760 Cost:  6.0441346 \n",
      "Prediction:\n",
      " [[155.44424]\n",
      " [182.05307]\n",
      " [181.96156]\n",
      " [195.99026]\n",
      " [139.58636]]\n",
      "770 Cost:  6.0137024 \n",
      "Prediction:\n",
      " [[155.43492]\n",
      " [182.05946]\n",
      " [181.95868]\n",
      " [195.98843]\n",
      " [139.59448]]\n",
      "780 Cost:  5.983471 \n",
      "Prediction:\n",
      " [[155.42561]\n",
      " [182.0658 ]\n",
      " [181.95581]\n",
      " [195.9866 ]\n",
      " [139.60258]]\n",
      "790 Cost:  5.9534073 \n",
      "Prediction:\n",
      " [[155.41637]\n",
      " [182.07213]\n",
      " [181.95293]\n",
      " [195.98477]\n",
      " [139.61067]]\n",
      "800 Cost:  5.923486 \n",
      "Prediction:\n",
      " [[155.40712]\n",
      " [182.07843]\n",
      " [181.95006]\n",
      " [195.98297]\n",
      " [139.61874]]\n",
      "810 Cost:  5.893714 \n",
      "Prediction:\n",
      " [[155.3979 ]\n",
      " [182.08473]\n",
      " [181.9472 ]\n",
      " [195.98117]\n",
      " [139.6268 ]]\n",
      "820 Cost:  5.864089 \n",
      "Prediction:\n",
      " [[155.38869]\n",
      " [182.091  ]\n",
      " [181.94434]\n",
      " [195.97935]\n",
      " [139.63481]]\n",
      "830 Cost:  5.834733 \n",
      "Prediction:\n",
      " [[155.37955]\n",
      " [182.09724]\n",
      " [181.94151]\n",
      " [195.97754]\n",
      " [139.6428 ]]\n",
      "840 Cost:  5.8054166 \n",
      "Prediction:\n",
      " [[155.37039]\n",
      " [182.10352]\n",
      " [181.93867]\n",
      " [195.97575]\n",
      " [139.65077]]\n",
      "850 Cost:  5.7762995 \n",
      "Prediction:\n",
      " [[155.36127]\n",
      " [182.10974]\n",
      " [181.93585]\n",
      " [195.97397]\n",
      " [139.65872]]\n",
      "860 Cost:  5.747351 \n",
      "Prediction:\n",
      " [[155.35217]\n",
      " [182.11594]\n",
      " [181.93303]\n",
      " [195.97217]\n",
      " [139.66666]]\n",
      "870 Cost:  5.718541 \n",
      "Prediction:\n",
      " [[155.34311]\n",
      " [182.12215]\n",
      " [181.93024]\n",
      " [195.97041]\n",
      " [139.67458]]\n",
      "880 Cost:  5.689887 \n",
      "Prediction:\n",
      " [[155.33406]\n",
      " [182.12831]\n",
      " [181.92741]\n",
      " [195.96864]\n",
      " [139.68246]]\n",
      "890 Cost:  5.6614003 \n",
      "Prediction:\n",
      " [[155.32503]\n",
      " [182.13446]\n",
      " [181.92462]\n",
      " [195.96686]\n",
      " [139.69032]]\n",
      "900 Cost:  5.6330385 \n",
      "Prediction:\n",
      " [[155.31604]\n",
      " [182.14061]\n",
      " [181.92181]\n",
      " [195.9651 ]\n",
      " [139.69818]]\n",
      "910 Cost:  5.6048536 \n",
      "Prediction:\n",
      " [[155.30705]\n",
      " [182.14673]\n",
      " [181.91904]\n",
      " [195.96333]\n",
      " [139.706  ]]\n",
      "920 Cost:  5.5768223 \n",
      "Prediction:\n",
      " [[155.29811]\n",
      " [182.15283]\n",
      " [181.91626]\n",
      " [195.96158]\n",
      " [139.7138 ]]\n",
      "930 Cost:  5.548926 \n",
      "Prediction:\n",
      " [[155.28918]\n",
      " [182.15894]\n",
      " [181.9135 ]\n",
      " [195.95985]\n",
      " [139.72159]]\n",
      "940 Cost:  5.521165 \n",
      "Prediction:\n",
      " [[155.28029]\n",
      " [182.16502]\n",
      " [181.91072]\n",
      " [195.9581 ]\n",
      " [139.72935]]\n",
      "950 Cost:  5.493583 \n",
      "Prediction:\n",
      " [[155.27141]\n",
      " [182.17108]\n",
      " [181.90797]\n",
      " [195.95638]\n",
      " [139.73709]]\n",
      "960 Cost:  5.4661155 \n",
      "Prediction:\n",
      " [[155.26254]\n",
      " [182.17712]\n",
      " [181.90521]\n",
      " [195.95464]\n",
      " [139.74481]]\n",
      "970 Cost:  5.4388437 \n",
      "Prediction:\n",
      " [[155.25372]\n",
      " [182.18317]\n",
      " [181.9025 ]\n",
      " [195.95291]\n",
      " [139.7525 ]]\n",
      "980 Cost:  5.411696 \n",
      "Prediction:\n",
      " [[155.2449 ]\n",
      " [182.18918]\n",
      " [181.89977]\n",
      " [195.95119]\n",
      " [139.76016]]\n",
      "990 Cost:  5.384702 \n",
      "Prediction:\n",
      " [[155.23613]\n",
      " [182.19516]\n",
      " [181.89702]\n",
      " [195.94948]\n",
      " [139.76782]]\n",
      "1000 Cost:  5.357875 \n",
      "Prediction:\n",
      " [[155.22737]\n",
      " [182.20114]\n",
      " [181.89433]\n",
      " [195.94777]\n",
      " [139.77545]]\n",
      "1010 Cost:  5.331155 \n",
      "Prediction:\n",
      " [[155.21864]\n",
      " [182.2071 ]\n",
      " [181.8916 ]\n",
      " [195.94606]\n",
      " [139.78307]]\n",
      "1020 Cost:  5.3046026 \n",
      "Prediction:\n",
      " [[155.20992]\n",
      " [182.21304]\n",
      " [181.88892]\n",
      " [195.94435]\n",
      " [139.79065]]\n",
      "1030 Cost:  5.2781577 \n",
      "Prediction:\n",
      " [[155.20123]\n",
      " [182.21898]\n",
      " [181.8862 ]\n",
      " [195.94266]\n",
      " [139.79823]]\n",
      "1040 Cost:  5.2519 \n",
      "Prediction:\n",
      " [[155.19257]\n",
      " [182.22488]\n",
      " [181.88351]\n",
      " [195.94096]\n",
      " [139.80577]]\n",
      "1050 Cost:  5.2257433 \n",
      "Prediction:\n",
      " [[155.18391]\n",
      " [182.23079]\n",
      " [181.88084]\n",
      " [195.93929]\n",
      " [139.81331]]\n",
      "1060 Cost:  5.1997304 \n",
      "Prediction:\n",
      " [[155.17531]\n",
      " [182.2367 ]\n",
      " [181.87816]\n",
      " [195.93764]\n",
      " [139.82082]]\n",
      "1070 Cost:  5.173875 \n",
      "Prediction:\n",
      " [[155.1667 ]\n",
      " [182.24255]\n",
      " [181.8755 ]\n",
      " [195.93594]\n",
      " [139.82831]]\n",
      "1080 Cost:  5.14816 \n",
      "Prediction:\n",
      " [[155.15813]\n",
      " [182.2484 ]\n",
      " [181.87283]\n",
      " [195.93427]\n",
      " [139.83577]]\n",
      "1090 Cost:  5.1225576 \n",
      "Prediction:\n",
      " [[155.14957]\n",
      " [182.25424]\n",
      " [181.87018]\n",
      " [195.93259]\n",
      " [139.84322]]\n",
      "1100 Cost:  5.0971217 \n",
      "Prediction:\n",
      " [[155.14105]\n",
      " [182.26007]\n",
      " [181.86754]\n",
      " [195.93094]\n",
      " [139.85065]]\n",
      "1110 Cost:  5.0717783 \n",
      "Prediction:\n",
      " [[155.13252]\n",
      " [182.26588]\n",
      " [181.8649 ]\n",
      " [195.92929]\n",
      " [139.85805]]\n",
      "1120 Cost:  5.046668 \n",
      "Prediction:\n",
      " [[155.12405]\n",
      " [182.27165]\n",
      " [181.86227]\n",
      " [195.92763]\n",
      " [139.86542]]\n",
      "1130 Cost:  5.0216126 \n",
      "Prediction:\n",
      " [[155.11559]\n",
      " [182.27742]\n",
      " [181.85963]\n",
      " [195.926  ]\n",
      " [139.87279]]\n",
      "1140 Cost:  4.996695 \n",
      "Prediction:\n",
      " [[155.10715]\n",
      " [182.2832 ]\n",
      " [181.85703]\n",
      " [195.92436]\n",
      " [139.88013]]\n",
      "1150 Cost:  4.9719424 \n",
      "Prediction:\n",
      " [[155.09872]\n",
      " [182.28893]\n",
      " [181.85442]\n",
      " [195.92271]\n",
      " [139.88745]]\n",
      "1160 Cost:  4.9473205 \n",
      "Prediction:\n",
      " [[155.09035]\n",
      " [182.29466]\n",
      " [181.85182]\n",
      " [195.9211 ]\n",
      " [139.89476]]\n",
      "1170 Cost:  4.9228067 \n",
      "Prediction:\n",
      " [[155.08197]\n",
      " [182.30038]\n",
      " [181.84923]\n",
      " [195.91948]\n",
      " [139.90204]]\n",
      "1180 Cost:  4.8984447 \n",
      "Prediction:\n",
      " [[155.07362]\n",
      " [182.30608]\n",
      " [181.84662]\n",
      " [195.91783]\n",
      " [139.90929]]\n",
      "1190 Cost:  4.8742104 \n",
      "Prediction:\n",
      " [[155.0653 ]\n",
      " [182.31175]\n",
      " [181.84404]\n",
      " [195.91623]\n",
      " [139.91655]]\n",
      "1200 Cost:  4.850067 \n",
      "Prediction:\n",
      " [[155.05699]\n",
      " [182.31743]\n",
      " [181.84146]\n",
      " [195.91463]\n",
      " [139.92378]]\n",
      "1210 Cost:  4.82611 \n",
      "Prediction:\n",
      " [[155.0487 ]\n",
      " [182.32307]\n",
      " [181.83888]\n",
      " [195.913  ]\n",
      " [139.93095]]\n",
      "1220 Cost:  4.802228 \n",
      "Prediction:\n",
      " [[155.04045]\n",
      " [182.32872]\n",
      " [181.8363 ]\n",
      " [195.9114 ]\n",
      " [139.93816]]\n",
      "1230 Cost:  4.778522 \n",
      "Prediction:\n",
      " [[155.03223]\n",
      " [182.33435]\n",
      " [181.83377]\n",
      " [195.90982]\n",
      " [139.94533]]\n",
      "1240 Cost:  4.7549458 \n",
      "Prediction:\n",
      " [[155.02402]\n",
      " [182.33995]\n",
      " [181.8312 ]\n",
      " [195.90825]\n",
      " [139.95245]]\n",
      "1250 Cost:  4.731501 \n",
      "Prediction:\n",
      " [[155.01581]\n",
      " [182.34552]\n",
      " [181.82867]\n",
      " [195.90665]\n",
      " [139.95956]]\n",
      "1260 Cost:  4.7081347 \n",
      "Prediction:\n",
      " [[155.00764]\n",
      " [182.3511 ]\n",
      " [181.82613]\n",
      " [195.90506]\n",
      " [139.96669]]\n",
      "1270 Cost:  4.6849127 \n",
      "Prediction:\n",
      " [[154.9995 ]\n",
      " [182.35667]\n",
      " [181.8236 ]\n",
      " [195.90349]\n",
      " [139.97377]]\n",
      "1280 Cost:  4.6618395 \n",
      "Prediction:\n",
      " [[154.99136]\n",
      " [182.36221]\n",
      " [181.82109]\n",
      " [195.9019 ]\n",
      " [139.98083]]\n",
      "1290 Cost:  4.638865 \n",
      "Prediction:\n",
      " [[154.98326]\n",
      " [182.36775]\n",
      " [181.81857]\n",
      " [195.90034]\n",
      " [139.98788]]\n",
      "1300 Cost:  4.616014 \n",
      "Prediction:\n",
      " [[154.97517]\n",
      " [182.37326]\n",
      " [181.81606]\n",
      " [195.89879]\n",
      " [139.99492]]\n",
      "1310 Cost:  4.5932913 \n",
      "Prediction:\n",
      " [[154.9671 ]\n",
      " [182.37877]\n",
      " [181.81355]\n",
      " [195.89723]\n",
      " [140.0019 ]]\n",
      "1320 Cost:  4.5706697 \n",
      "Prediction:\n",
      " [[154.95906]\n",
      " [182.38426]\n",
      " [181.81105]\n",
      " [195.89568]\n",
      " [140.00891]]\n",
      "1330 Cost:  4.5482054 \n",
      "Prediction:\n",
      " [[154.95103]\n",
      " [182.38972]\n",
      " [181.80856]\n",
      " [195.89413]\n",
      " [140.01587]]\n",
      "1340 Cost:  4.5258374 \n",
      "Prediction:\n",
      " [[154.94304]\n",
      " [182.39519]\n",
      " [181.80608]\n",
      " [195.8926 ]\n",
      " [140.02283]]\n",
      "1350 Cost:  4.5036163 \n",
      "Prediction:\n",
      " [[154.93507]\n",
      " [182.40063]\n",
      " [181.8036 ]\n",
      " [195.89105]\n",
      " [140.02975]]\n",
      "1360 Cost:  4.4815 \n",
      "Prediction:\n",
      " [[154.92711]\n",
      " [182.40605]\n",
      " [181.80112]\n",
      " [195.88951]\n",
      " [140.03665]]\n",
      "1370 Cost:  4.4594936 \n",
      "Prediction:\n",
      " [[154.91916]\n",
      " [182.41147]\n",
      " [181.79868]\n",
      " [195.88799]\n",
      " [140.04355]]\n",
      "1380 Cost:  4.437638 \n",
      "Prediction:\n",
      " [[154.91127]\n",
      " [182.41685]\n",
      " [181.7962 ]\n",
      " [195.88647]\n",
      " [140.05043]]\n",
      "1390 Cost:  4.415864 \n",
      "Prediction:\n",
      " [[154.90335]\n",
      " [182.42224]\n",
      " [181.79376]\n",
      " [195.88495]\n",
      " [140.05727]]\n",
      "1400 Cost:  4.394198 \n",
      "Prediction:\n",
      " [[154.89551]\n",
      " [182.42764]\n",
      " [181.7913 ]\n",
      " [195.88344]\n",
      " [140.06412]]\n",
      "1410 Cost:  4.3726826 \n",
      "Prediction:\n",
      " [[154.88765]\n",
      " [182.43298]\n",
      " [181.78886]\n",
      " [195.88191]\n",
      " [140.07092]]\n",
      "1420 Cost:  4.351255 \n",
      "Prediction:\n",
      " [[154.87982]\n",
      " [182.43834]\n",
      " [181.78644]\n",
      " [195.88039]\n",
      " [140.07773]]\n",
      "1430 Cost:  4.3299537 \n",
      "Prediction:\n",
      " [[154.872  ]\n",
      " [182.44365]\n",
      " [181.78401]\n",
      " [195.8789 ]\n",
      " [140.0845 ]]\n",
      "1440 Cost:  4.3087745 \n",
      "Prediction:\n",
      " [[154.86421]\n",
      " [182.44896]\n",
      " [181.78159]\n",
      " [195.87741]\n",
      " [140.09126]]\n",
      "1450 Cost:  4.287736 \n",
      "Prediction:\n",
      " [[154.85645]\n",
      " [182.45424]\n",
      " [181.77917]\n",
      " [195.8759 ]\n",
      " [140.09799]]\n",
      "1460 Cost:  4.266756 \n",
      "Prediction:\n",
      " [[154.84872]\n",
      " [182.45956]\n",
      " [181.77678]\n",
      " [195.87444]\n",
      " [140.10474]]\n",
      "1470 Cost:  4.2459116 \n",
      "Prediction:\n",
      " [[154.84097]\n",
      " [182.46481]\n",
      " [181.77438]\n",
      " [195.87294]\n",
      " [140.11143]]\n",
      "1480 Cost:  4.2251883 \n",
      "Prediction:\n",
      " [[154.83328]\n",
      " [182.47008]\n",
      " [181.77199]\n",
      " [195.87146]\n",
      " [140.11812]]\n",
      "1490 Cost:  4.204563 \n",
      "Prediction:\n",
      " [[154.8256 ]\n",
      " [182.47533]\n",
      " [181.76959]\n",
      " [195.87   ]\n",
      " [140.12479]]\n",
      "1500 Cost:  4.18406 \n",
      "Prediction:\n",
      " [[154.81793]\n",
      " [182.48055]\n",
      " [181.76721]\n",
      " [195.86852]\n",
      " [140.13142]]\n",
      "1510 Cost:  4.1636543 \n",
      "Prediction:\n",
      " [[154.81029]\n",
      " [182.48576]\n",
      " [181.76485]\n",
      " [195.86707]\n",
      " [140.13806]]\n",
      "1520 Cost:  4.1433825 \n",
      "Prediction:\n",
      " [[154.80267]\n",
      " [182.49095]\n",
      " [181.76247]\n",
      " [195.86559]\n",
      " [140.14467]]\n",
      "1530 Cost:  4.1231976 \n",
      "Prediction:\n",
      " [[154.79507]\n",
      " [182.49615]\n",
      " [181.76013]\n",
      " [195.86414]\n",
      " [140.15128]]\n",
      "1540 Cost:  4.103097 \n",
      "Prediction:\n",
      " [[154.78746]\n",
      " [182.50131]\n",
      " [181.75775]\n",
      " [195.86269]\n",
      " [140.15784]]\n",
      "1550 Cost:  4.083146 \n",
      "Prediction:\n",
      " [[154.77992]\n",
      " [182.50647]\n",
      " [181.75539]\n",
      " [195.86125]\n",
      " [140.1644 ]]\n",
      "1560 Cost:  4.0632753 \n",
      "Prediction:\n",
      " [[154.77237]\n",
      " [182.51163]\n",
      " [181.75307]\n",
      " [195.8598 ]\n",
      " [140.17094]]\n",
      "1570 Cost:  4.043523 \n",
      "Prediction:\n",
      " [[154.76483]\n",
      " [182.51674]\n",
      " [181.7507 ]\n",
      " [195.85834]\n",
      " [140.17744]]\n",
      "1580 Cost:  4.023878 \n",
      "Prediction:\n",
      " [[154.75735]\n",
      " [182.52188]\n",
      " [181.74838]\n",
      " [195.85693]\n",
      " [140.18396]]\n",
      "1590 Cost:  4.004355 \n",
      "Prediction:\n",
      " [[154.74988]\n",
      " [182.52698]\n",
      " [181.74606]\n",
      " [195.8555 ]\n",
      " [140.19044]]\n",
      "1600 Cost:  3.9849052 \n",
      "Prediction:\n",
      " [[154.7424 ]\n",
      " [182.53207]\n",
      " [181.74376]\n",
      " [195.85408]\n",
      " [140.19691]]\n",
      "1610 Cost:  3.9655623 \n",
      "Prediction:\n",
      " [[154.73495]\n",
      " [182.53714]\n",
      " [181.74142]\n",
      " [195.85265]\n",
      " [140.20337]]\n",
      "1620 Cost:  3.9463577 \n",
      "Prediction:\n",
      " [[154.72754]\n",
      " [182.5422 ]\n",
      " [181.73914]\n",
      " [195.85123]\n",
      " [140.2098 ]]\n",
      "1630 Cost:  3.9272513 \n",
      "Prediction:\n",
      " [[154.72014]\n",
      " [182.54724]\n",
      " [181.73683]\n",
      " [195.84981]\n",
      " [140.2162 ]]\n",
      "1640 Cost:  3.9082084 \n",
      "Prediction:\n",
      " [[154.71275]\n",
      " [182.55229]\n",
      " [181.73453]\n",
      " [195.8484 ]\n",
      " [140.2226 ]]\n",
      "1650 Cost:  3.8893008 \n",
      "Prediction:\n",
      " [[154.70541]\n",
      " [182.55733]\n",
      " [181.73224]\n",
      " [195.84702]\n",
      " [140.22897]]\n",
      "1660 Cost:  3.8704848 \n",
      "Prediction:\n",
      " [[154.69806]\n",
      " [182.56232]\n",
      " [181.72997]\n",
      " [195.8456 ]\n",
      " [140.23535]]\n",
      "1670 Cost:  3.8517566 \n",
      "Prediction:\n",
      " [[154.69073]\n",
      " [182.56732]\n",
      " [181.72769]\n",
      " [195.84422]\n",
      " [140.2417 ]]\n",
      "1680 Cost:  3.833163 \n",
      "Prediction:\n",
      " [[154.68343]\n",
      " [182.57228]\n",
      " [181.72542]\n",
      " [195.84282]\n",
      " [140.24802]]\n",
      "1690 Cost:  3.8146222 \n",
      "Prediction:\n",
      " [[154.67615]\n",
      " [182.57727]\n",
      " [181.72314]\n",
      " [195.84142]\n",
      " [140.25433]]\n",
      "1700 Cost:  3.7962105 \n",
      "Prediction:\n",
      " [[154.66888]\n",
      " [182.58221]\n",
      " [181.72087]\n",
      " [195.84006]\n",
      " [140.26062]]\n",
      "1710 Cost:  3.777866 \n",
      "Prediction:\n",
      " [[154.66162]\n",
      " [182.58717]\n",
      " [181.71863]\n",
      " [195.83868]\n",
      " [140.26689]]\n",
      "1720 Cost:  3.7596588 \n",
      "Prediction:\n",
      " [[154.6544 ]\n",
      " [182.5921 ]\n",
      " [181.7164 ]\n",
      " [195.83731]\n",
      " [140.27316]]\n",
      "1730 Cost:  3.7415435 \n",
      "Prediction:\n",
      " [[154.6472 ]\n",
      " [182.59702]\n",
      " [181.71414]\n",
      " [195.83592]\n",
      " [140.27939]]\n",
      "1740 Cost:  3.7235272 \n",
      "Prediction:\n",
      " [[154.64001]\n",
      " [182.60191]\n",
      " [181.71191]\n",
      " [195.83456]\n",
      " [140.28561]]\n",
      "1750 Cost:  3.7055938 \n",
      "Prediction:\n",
      " [[154.63283]\n",
      " [182.6068 ]\n",
      " [181.70969]\n",
      " [195.8332 ]\n",
      " [140.29181]]\n",
      "1760 Cost:  3.6877952 \n",
      "Prediction:\n",
      " [[154.6257 ]\n",
      " [182.61168]\n",
      " [181.70747]\n",
      " [195.83183]\n",
      " [140.29799]]\n",
      "1770 Cost:  3.6700199 \n",
      "Prediction:\n",
      " [[154.61856]\n",
      " [182.61655]\n",
      " [181.70523]\n",
      " [195.83049]\n",
      " [140.30417]]\n",
      "1780 Cost:  3.652391 \n",
      "Prediction:\n",
      " [[154.61145]\n",
      " [182.6214 ]\n",
      " [181.70303]\n",
      " [195.82915]\n",
      " [140.31032]]\n",
      "1790 Cost:  3.6348395 \n",
      "Prediction:\n",
      " [[154.60435]\n",
      " [182.62624]\n",
      " [181.70084]\n",
      " [195.8278 ]\n",
      " [140.31647]]\n",
      "1800 Cost:  3.617391 \n",
      "Prediction:\n",
      " [[154.59727]\n",
      " [182.63104]\n",
      " [181.69862]\n",
      " [195.82645]\n",
      " [140.32259]]\n",
      "1810 Cost:  3.600061 \n",
      "Prediction:\n",
      " [[154.59024]\n",
      " [182.63586]\n",
      " [181.69646]\n",
      " [195.82513]\n",
      " [140.32869]]\n",
      "1820 Cost:  3.5827765 \n",
      "Prediction:\n",
      " [[154.58318]\n",
      " [182.64066]\n",
      " [181.69424]\n",
      " [195.82379]\n",
      " [140.33475]]\n",
      "1830 Cost:  3.565612 \n",
      "Prediction:\n",
      " [[154.57617]\n",
      " [182.64545]\n",
      " [181.69208]\n",
      " [195.82245]\n",
      " [140.34084]]\n",
      "1840 Cost:  3.5485313 \n",
      "Prediction:\n",
      " [[154.56918]\n",
      " [182.65022]\n",
      " [181.6899 ]\n",
      " [195.82114]\n",
      " [140.3469 ]]\n",
      "1850 Cost:  3.531552 \n",
      "Prediction:\n",
      " [[154.56221]\n",
      " [182.65497]\n",
      " [181.6877 ]\n",
      " [195.81981]\n",
      " [140.35292]]\n",
      "1860 Cost:  3.5146422 \n",
      "Prediction:\n",
      " [[154.55522]\n",
      " [182.65971]\n",
      " [181.68555]\n",
      " [195.8185 ]\n",
      " [140.35893]]\n",
      "1870 Cost:  3.4978287 \n",
      "Prediction:\n",
      " [[154.5483 ]\n",
      " [182.66446]\n",
      " [181.68338]\n",
      " [195.8172 ]\n",
      " [140.36494]]\n",
      "1880 Cost:  3.4811206 \n",
      "Prediction:\n",
      " [[154.54137]\n",
      " [182.66917]\n",
      " [181.68123]\n",
      " [195.81589]\n",
      " [140.37093]]\n",
      "1890 Cost:  3.4644878 \n",
      "Prediction:\n",
      " [[154.53447]\n",
      " [182.67389]\n",
      " [181.67908]\n",
      " [195.81458]\n",
      " [140.3769 ]]\n",
      "1900 Cost:  3.4479318 \n",
      "Prediction:\n",
      " [[154.52757]\n",
      " [182.67859]\n",
      " [181.67693]\n",
      " [195.8133 ]\n",
      " [140.38286]]\n",
      "1910 Cost:  3.4315064 \n",
      "Prediction:\n",
      " [[154.52069]\n",
      " [182.68326]\n",
      " [181.6748 ]\n",
      " [195.81198]\n",
      " [140.38878]]\n",
      "1920 Cost:  3.4151702 \n",
      "Prediction:\n",
      " [[154.51385]\n",
      " [182.68793]\n",
      " [181.67268]\n",
      " [195.81068]\n",
      " [140.3947 ]]\n",
      "1930 Cost:  3.3989062 \n",
      "Prediction:\n",
      " [[154.50703]\n",
      " [182.69258]\n",
      " [181.67055]\n",
      " [195.80939]\n",
      " [140.4006 ]]\n",
      "1940 Cost:  3.382703 \n",
      "Prediction:\n",
      " [[154.50021]\n",
      " [182.69724]\n",
      " [181.66843]\n",
      " [195.80814]\n",
      " [140.4065 ]]\n",
      "1950 Cost:  3.3665862 \n",
      "Prediction:\n",
      " [[154.49341]\n",
      " [182.70187]\n",
      " [181.6663 ]\n",
      " [195.80682]\n",
      " [140.41237]]\n",
      "1960 Cost:  3.350598 \n",
      "Prediction:\n",
      " [[154.48663]\n",
      " [182.70648]\n",
      " [181.6642 ]\n",
      " [195.80556]\n",
      " [140.41821]]\n",
      "1970 Cost:  3.3346786 \n",
      "Prediction:\n",
      " [[154.47989]\n",
      " [182.7111 ]\n",
      " [181.66211]\n",
      " [195.80429]\n",
      " [140.42406]]\n",
      "1980 Cost:  3.3188138 \n",
      "Prediction:\n",
      " [[154.47311]\n",
      " [182.71568]\n",
      " [181.65997]\n",
      " [195.80301]\n",
      " [140.42986]]\n",
      "1990 Cost:  3.303062 \n",
      "Prediction:\n",
      " [[154.4664 ]\n",
      " [182.72029]\n",
      " [181.65791]\n",
      " [195.80176]\n",
      " [140.43567]]\n",
      "2000 Cost:  3.2874 \n",
      "Prediction:\n",
      " [[154.4597 ]\n",
      " [182.72485]\n",
      " [181.65582]\n",
      " [195.80049]\n",
      " [140.44147]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]], dtype=np.float32)\n",
    "y_data = np.array([[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]], dtype=np.float32)\n",
    "\n",
    "W = tf.Variable(tf.random.normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5)\n",
    "\n",
    "def run_optimization():\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(x_data,W) + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "    gradients = tape.gradient(cost, [W,b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W,b]))\n",
    "    return cost, hypothesis\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val = run_optimization()\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val.numpy(), \"\\nPrediction:\\n\", hy_val.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*리스트 indexing, slicing, iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  6 10]\n",
      "[ 9 10 11 12]\n",
      "[ 9 10 11 12]\n",
      "[ 9 10 11 12]\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,], [5,6,7,8], [9,10,11,12]])\n",
    "#a[행: ,인덱스]\n",
    "print(a[:,1])\n",
    "print(a[-1])\n",
    "print(a[-1, :])\n",
    "print(a[-1, ...])\n",
    "print(a[0:2 :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
